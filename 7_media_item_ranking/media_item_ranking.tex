\chapter{Media Item Ranking}
\label{sec:media-item-ranking}

% the code below specifies where the figures are stored
\ifpdf
    \graphicspath{{7_media_item_ranking/figures/PNG/}{7_media_item_ranking/figures/PDF/}{7_media_item_ranking/figures/}}
\else
    \graphicspath{{7_media_item_ranking/figures/EPS/}{7_media_item_ranking/figures/}}
\fi

\section{Introduction}

In the previous chapter, we have motivated and shown methods
to deduplicate exact duplicate and near-duplicate media items.
The application screenshots that can be seen in \autoref{fig:topvsfashionshow}
and \autoref{fig:topgrammy} show the most intuitive ranking criterion
one can imagine: ranking by occurrence popularity.
The more often a~media item (or a~near-duplicate of it)
appears in any of the considered social networks, 
the higher it should be ranked.
Essentially, ranking by occurrence popularity (or media item cluster size)
disregards one of the most valuable features of social networks: 
the social aspects.
In consequence, in this chapter, we will introduce
further media item ranking criteria that,
together with media item cluster size,
will allow us to come up with more adequate social media item ranking mechanisms.

\section{Evaluating Subjective Data}

Evaluating subjective data, like \emph{the} correct ranking
for a~set of media items, is a~challenging task.
For different users, there may be different optimal settings.
A~common subjective evaluation technique
is the Mean~Opinion Score (MOS)~\cite{itu1998mos}.
Traditionally, MOS is used for conducting subjective evaluations
of telephony network transmission quality,
however, more recently, MOS has also found
wider usage in the multimedia community
for evaluating \emph{per se} subjective things
like perceived quality from the users' perspective. 
Therefore, a~set of standard, subjective tests are conducted,
where a~number of users rate the quality of test samples
with scores ranging from 1 (worst) to 5 (best).
The actual MOS is then the arithmetic mean of all individual scores.
Given a subjective evaluation criterion
like the correctness of a~ranking,
MOS provides a~meaningful way to judge the overall quality of our approach.

\section{Media Item Ranking Criteria}

In this section, we describe several criteria that can serve to rank
media items retrieved from social networks. 
We base these criteria on the information available from
the media item extractors described in \autoref{cha:media-item-extraction},
which given event-related search terms
extract raw binary media items and associated microposts
from multiple social networks.

\subsection{Visual Ranking Criteria} \label{sec:visualrankingcriteria}

This category regards the contents of photos and videos.
We distinguish \emph{low-} and \emph{high-level} visual ranking criteria.
High-level criteria are, \emph{e.g.}, logo detection,
face recognition, and camera shot separation.
Low-level criteria are, \emph{e.g.}, file size, resolution,
duration of a~video, geolocation, and time.
Via OCR, contained characters can be treated as a~textual features.

\subsection{Audial Ranking Criteria}

This category regards the audio track of videos.
\emph{High-level} ranking criteria are the presence or absence
of silence, music, speech, or a mixture thereof.
Similar to visual features before,
audial \emph{low-level} features are the average bit rate,
volume, possibly distorted areas, \emph{etc}.
Through audio-transcription, speech can be treated as a~textual feature.

\subsection{Textual Ranking Criteria}

This category regards the microposts that accompany media items.
Typically, microposts provide a~description of media items.
Using named-entity disambiguation tools,
textual content can be linked to LOD cloud concepts~\cite{Facebook2011}.
We have described micropost annotation in detail in \autoref{cha:micropost-annotation}.

\subsection{Social Ranking Criteria}

This category regards social network effects like shares, mentions,
view counts, expressions of (dis)likes, user diversity, \emph{etc}.
Prior work~\cite{khrouf2012aggregatingsocialmedia}
allows us to not only examine these effects
on a~\emph{single} social network,
but in a~\emph{network-agnostic} way across multiple social networks.
We will detail social aspects more later on in this chapter.

\subsection{Aesthetic Ranking Criteria}

This category regards the desired outcome after the ranking, \emph{i.e.},
the media gallery that illustrates a~given event and its atmosphere.
Studies exist for the aesthetics of
automatic photo book layout~\cite{sandhaus2011photobook},
photo aesthetics \emph{per se}~\cite{obrador2012photoaesthetics},
video and music playlist generation~\cite{knees2006musicplaylist,davidson2010videorecommendation},
however, to the best of our knowledge,
no media gallery composition aesthetics studies exist
that examine mixing video \emph{and} photo media items.

\section{Social Interactions Abstraction Layer}

As we have described in \autoref{cha:social-networks},
social networks have different paradigms of social interactions.
In \autoref{sec:data-format}, we have briefly presented the overall
abstraction layer on top of the native data formats
of all considered social networks in order to gain
an agnostic view on the underlying social networks.
In this section, we detail the part of the abstraction layer
that models the network-specific social interaction patterns.
Those interaction patterns must be exposed by the social network 
via specific API calls in order to be considered,
which only is the case for a~subset of the social networks we deal with.
In the subsections below, we have listed
how we abstract the social interactions in question on each social network.
In our concrete implementation, we differ unknown values
that are returned as \texttt{null}, \emph{i.e.},
where the information is not exposed,
from \texttt{0} values, where the value is known to be zero.
We briefly recall the social interactions part
of the abstraction layer's data format:

\begin{description}
  \item[\texttt{socialInteractions}] Container for social
    interactions
  \begin{description}  
  \item[\texttt{likes}] Number of times a~micropost was liked, or
    \texttt{null}
  \item[\texttt{shares}] Number of times a~micropost was shared, or
    \texttt{null}
  \item[\texttt{comments}] Number of comments a~micropost
    received, or \texttt{null}
  \item[\texttt{views}] Number of views a~micropost reached, or
    \texttt{null}
  \end{description}    
\end{description}

\subsection{Social Interaction ``Likes''}

We abstract the social interaction of liking a~media item
as instances of the following network-specific social interactions:

\begin{small_itemize}
  \item[] Facebook Like
  \item[] \googleplus \plusone
  \item[] Instagram Like
  \item[] Flickr Favorite
  \item[] YouTube Like, YouTube Favorite
  \item[] Twitter Favorite
\end{small_itemize}  

\subsection{Social Interaction ``Shares''}

We abstract the social interaction of resharing a~media item
as instances of the following network-specific social interactions:

\begin{small_itemize}
  \item[] Facebook Share
  \item[] \googleplus Share
  \item[] Twitter native ReTweet
\end{small_itemize}

\subsection{Social Interaction ``Comments''}

We abstract the social interaction of commenting on a~media item
as instances of the following network-specific social interactions:

\begin{small_itemize}
  \item[] Facebook Comments
  \item[] \googleplus Comments
  \item[] Instagram Comments
  \item[] Twitter manual, non-native ReTweet, @Replies
  \item[] Twitpic Comments
  \item[] MobyPicture Comments
  \item[] Flickr Comments
\end{small_itemize}

\subsection{Social Interaction ``Views''}

We abstract the social interaction of viewing a~media item
as instances of the following network-specific social interactions:

\begin{small_itemize}
  \item[] YouTube Views
  \item[] Flickr Views
  \item[] Twitpic Views
  \item[] Mobypicture Views
\end{small_itemize}

\section{Merging Social Interactions}

If a~set of media items is similar enough to be clustered
under the criteria that were detailed in
\autoref{cha:media-item-deduplication},
we can treat the whole of the cluster
as if it were just one media item.
Therefore, we need to specify a~merging strategy
for the associated data of the individual media items
in the particular cluster.
\autoref{code:merging} shows the pseudocode of the merging algorithm.
During the merging step,
we treat unknown values represented as \texttt{null} as \texttt{0}.
The algorithm accumulates individual social interactions
and assigns the accumulated social interactions to the cluster.

\begin{lstlisting}[caption=Pseudocode of the social interactions merging algorithm,
  label=code:merging, float]
for cluster in clusters
  likes = shares = views = comments = 0
  for mediaItem in cluster
    likes += mediaItem.likes ? mediaItem.likes : 0
    shares += mediaItem.shares ? mediaItem.shares : 0
    comments += mediaItem.comments ? mediaItem.comments : 0
    views += mediaItem.views ? mediaItem.views : 0
  end for
  cluster.socialInteractions.likes = likes
  cluster.socialInteractions.shares = shares
  cluster.socialInteractions.comments = comments
  cluster.socialInteractions.views = views
end for     
\end{lstlisting}

\section{Selection of a Cluster's Visual Representative}  

As outlined in the previous section, similar enough media items
are clustered and treated as just one media item.
The previous section introduced
a~merging algorithm for the social interactions data.
In this section, we introduce an algorithm for the selection of
a~cluster's visual representative.
Naturally, through the way the clustering algorithm works,
the contained media items are already visually similar. 
In consequence, we fall back to using \emph{low-level}
visual ranking criteria as defined in \autoref{sec:visualrankingcriteria}.
\autoref{code:clusterrepresentative} shows the cluster representative
selection algorithm, which is based on the low-level feature \emph{resolution}.
The algorithm selects the media item with the highest megapixel resolution
as the cluster representative.

\begin{lstlisting}[caption=Pseudocode of the cluster representative selection algorithm,
  label=code:clusterrepresentative, float]
maxPixels = 0
clusterRepresentative = null
for mediaItem in cluster
  resolution = mediaItem.width * mediaItem.height
  if resolution >= maxPixels
    maxPixels = resolution
    clusterRepresentative = mediaItem
  end if  
end for
return clusterRepresentative     
\end{lstlisting}

\section{Ranking Media Item Clusters}

Up to now, we have shown how media item clusters are formed,
how each cluster's social interactions data are accumulated,
and how a~cluster representative media item is chosen.
In this section, we finally describe a~ranking formula to rank
a~set of media clusters that match a~given query.


\section{Conclusion}

\section*{Chapter Notes}
This chapter is partly based on the following publications:
\todo{Add publications}