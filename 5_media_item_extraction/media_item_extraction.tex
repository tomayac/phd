\chapter{Media Item Extraction}

% the code below specifies where the figures are stored
\ifpdf
    \graphicspath{{5_media_item_extraction/figures/PNG/}{5_media_item_extraction/figures/PDF/}{5_media_item_extraction/figures/}}
\else
    \graphicspath{{5_media_item_extraction/figures/EPS/}{5_media_item_extraction/figures/}}
\fi

\section{Introduction}
\label{sec:introduction}

Before the rise of social networks,
event coverage was mostly an affair of professional news agencies.
The widespread availability of mobile phones
with higher resolution cameras has transformed
citizens into witnesses who are used to comment
and share media illustrating events on social networks.
Some examples with global impact
include the shootings in
Ut{\o}ya\footnote{\url{http://en.wikipedia.org/wiki/2011_Norway_attacks},
accessed November 21, 2012},
which first appeared on Twitter,
the capture and arrest of Muammar
Gaddafi\footnote{\url{http://en.wikipedia.org/wiki/Death_of_Muammar_Gaddafi},
accessed November 21, 2012},
which first appeared on YouTube,
or the emergency ditching of a plane in the Hudson
river\footnote{\url{http://en.wikipedia.org/wiki/US_Airways_Flight_1549},
accessed November 21, 2012},
which first appeared on Twitpic.
Some news
communities\footnote{\url{http://www.citizenside.com/},
accessed November 21, 2012}
have even specialized in aggregating and brokering
such user-generated content.
Events, such as sports matches or concerts are 
largely illustrated by social media,
albeit distributed over many social networks.

In this section, we tackle the challenge of reconciling
social media that illustrates known events,
but that is spread over various social networks
with the objective of creating visual summaries of them.
We propose a social network agnostic
approach for the extraction of images and videos covering events. We want to emphasize that we do \emph{not} perform event detection: 
the events we are dealing with are known beforehand
and we use specific human-chosen search terms
to find illustrating media.

\section{Social Networks and Media Items}                                    \label{sec:social-networks}

We first recall the definitions previously made in
\autoref{sec:definition} and add a formal definition
borrowed from~\cite{liu2011events}
of what we mean by \emph{event}.
Most social networks offer a search functionality that allows for
content to be retrieved based on search terms,
with or without more advanced search operators
such as exclusion, inclusion, phrase search, \emph{etc.}
Each social network has special constraints
regarding the supported search operators or filtering options.
We define the term \emph{media item extraction}
as follows.

\subsection{Definitions}

\begin{description}
  \item[Social Network:]
       A~social network is an online service or media platform
       that focuses on building and reflecting
       social relationships among people
       who share interests and/or activities.
  \item[Media Item:]
       A~media item is defined as an image or video
       file that gets distributed via a~social network.
  \item[Micropost:]
       A~micropost is defined as a~textual status message
       that can optionally be accompanied by a~media item.
  \item[Event:]
       An event is defined as a phenomenon that has happened
       or that is scheduled to happen.
       It is an observable occurrence grouping persons,
       places, times and activities while being often
       documented by people through different media.
  \item[Media Item Extraction:]
       The process of leveraging search functionalities of
       social networks to find references to media items,
       which allows for storing those media items in binary form.       
\end{description}

\section{Media Item Extraction}

An \emph{Application Programming Interface (API)}
is a programmatic specification intended to be used
as an interface by software components on client and server
to communicate with each other.
\emph{Web scraping} is the process of
automatically extracting information from Web pages.
Web scraping involves practical solutions based on
existing technologies that are often entirely \emph{ad hoc}.
Examples of such technologies are regular expressions,
Document Object Model (DOM)
parsing~\cite{lehors2004dom},
or CSS selectors~\cite{hunt2012cssselectors}.
The difference between \emph{Web scraping}
and the related concept of \emph{screen scraping}
is that screen scraping relies on the visual layout of a Web page,
while Web scraping relies on the textual
and/or hierarchical structure of Web pages.

Social networks are often perceived as
\emph{walled gardens}~\cite{simonds2008walledgarden},
as illustrated by David Simonds in \autoref{fig:walled-gardens}.
While some social networks (\emph{e.g.}, Twitter)
have full read and write access via specified APIs,
other social networks (\emph{e.g.}, \googleplus)
currently only have read APIs access.
In some cases, however, API access is too limited,
so that not all desired information gets exposed
(\emph{e.g.}, view counts with Img.ly),
which forces people interested in that data
to fall back to Web scraping.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.7\linewidth,
    trim=16px 17px 12px 15px,clip]{davidsimonds.jpg}
  \caption[David Simonds illustrates social networks as walled
    gardens.]
    {David Simonds illustrates social networks as walled
    gardens.}
  \label{fig:walled-gardens}
\end{figure}

\section{Media Extractor}
\label{sec:media-extractor}

In this section, we first introduce a common data format
that we have developed as an abstraction layer on top of the native
data formats used by the considered social networks.
We then explain the architecture
of different kinds of media item extractors.
Finally, we describe the various processing steps
applied to each collected media item.

\subsection{Abstraction Layer Data Format}
\label{sec:data-format}

Each social network uses a different data representation schema.
While all social networks with API access are
JSON-based~\cite{crockford2006json}, the differences in both 
social network class and media item support level,
outlined in detail in
\autoref{sec:description-of-popular-social-networks} and
\autoref{sec:classification-of-social-networks},
are also reflected in the returned JSON data.
We therefore propose a common abstraction layer 
on top of the native data formats of all considered social networks
outlined in \autoref{tab:platforms} in order to gain
an agnostic view on the underlying social networks.
Naturally, any abstraction can only represent the
least common multiple of all social networks.
We explain the abstraction layer in the following
with the help of a concrete example,
stemming from a query to the media collector
that gets explained in more detail
in the upcoming \autoref{sec:media-item-extractors}.
The media collector was used to query for media items
that match the search term \emph{hamburg}.
\autoref{code:facebook} shows sample output of the media extractor
for a Facebook post, which was processed
with named entity extraction and disambiguation 
as detailed in \autoref{cha:micropost-annotation}.

\begin{description}
  \item[\texttt{mediaUrl}] Deep link to a media item.
  \item[\texttt{posterUrl}] Deep link to a thumbnail for photos
    or still frame for videos.
  \item[\texttt{micropostUrl}] Deep link to the micropost on
    the social network.
  \item[\texttt{micropost}] Container for a micropost.
  \begin{description}
    \item[\texttt{html}] Text of the micropost with potential HTML
      markup.
    \item[\texttt{plainText}] Text of the micropost with
      potential HTML markup removed.
    \item[\texttt{entities}] Extracted and disambiguated
      named entities from the micropost text.
  \end{description}      
  \item[\texttt{userProfileUrl}] Deep link to the user's
    profile on the social network.
  \item[\texttt{type}] Type of the media item,
    can be \texttt{photo} or \texttt{video}.
  \item[\texttt{timestamp}] Number of milliseconds since
    1 January 1970 00:00:00 UTC when the micropost was
    published.
  \item[\texttt{publicationDate}] Date in ISO 8601
    format when the micropost was published. 
  \item[\texttt{socialInteractions}] Container for social
    interactions.
  \begin{description}  
  \item[\texttt{likes}] Number of times a micropost was liked, or
    \texttt{null}.
  \item[\texttt{shares}] Number of times a micropost was shared, or
    \texttt{null}.
  \item[\texttt{comments}] Number of comments a micropost
    received, or \texttt{null}.
  \item[\texttt{views}] Number of views a micropost reached, or
    \texttt{null}.
  \end{description}    
\end{description}

\begin{lstlisting}[caption={Sample output of the media extractor
  showing a Facebook post processed with named entity extraction
  and disambiguation (slightly edited for legibility).},
  label={code:facebook}]
{
  "mediaUrl": "http://video.ak.fbcdn.net/...",
  "posterUrl": "http://external.ak.fbcdn.net/...",
  "micropostUrl": "https://www.facebook.com/permalink.php?story_fbid=
    231781590231029&id=1254772464",
  "micropost": {
    "html": "Videoed between Hamburg and Snyder. Thought I would share.",
    "plainText": "Videoed between Hamburg and Snyder. Thought I would share.",
    "entities": [
      [
        {
          "name": "Hamburg",
          "relevance": 0.82274,
          "uri": "http://dbpedia.org/resource/Hamburg"
        },
        {
          "name": "Snyder",
          "relevance": 0.857,
          "uri": "http://dbpedia.org/resource/Snyder,_Texas"
        }
      ]
    ]
  },
  "userProfileUrl": "https://www.facebook.com/profile.php?id=1254772464",
  "type": "video",
  "timestamp": 1326371479000,
  "publicationDate": "2012-01-12T12:31:19Z",
  "socialInteractions": {
    "likes": 0,
    "shares": 0,
    "comments": 3,
    "views": null
  }
}
\end{lstlisting}

\subsection{Media Item Extractors}
\label{sec:media-item-extractors}

We have developed a combined media extractor composed of
separate media item extractors for the seven social networks
\googleplus, Myspace, Facebook, Twitter, Instagram, YouTube,
and Flickr, with additional support for the media sharing
platforms Img.ly, Imgur, Lockerz, Yfrog, MobyPicture, and Twitpic.
The media extractor takes as input a search term that is relevant
to a known event, \emph{e.g.}, the term \emph{boston celtics}
for a recent match of the Basketball team Boston Celtics.
This search term gets forwarded to the search APIs
of the social networks in parallel.
Each social network has a 30 seconds timeout window
to deliver its results.
When the timeout is reached,
or when all social networks have responded,
the available results are represented according to the data format
defined in \autoref{sec:data-format}.
Media items and the relevant metadata like view count, comments,
\emph{etc.} are retrieved either directly, or via Web scraping.
For some social networks, \emph{e.g.}, Img.ly
a combination of Web scraping and API access is required
since the API does not return all necessary fields
of our data format.

\subsubsection{Special Role of Twitter}

Twitter plays a special role, as it can be used as
a third-order support social network,
as detailed previously in
\autoref{sec:twitter}
and \autoref{sec:classification-of-social-networks}.
This means that the micropost text is located on Twitter,
but the referenced media items are located
on third party media platforms.
Due to the length limitation for tweets of 140 characters,
short URLs are used on the service.
We search for the search term in question (\emph{e.g.},
following up from the example before, \emph{boston celtics}),
but combine it with the short URL domain parts of
the media platforms.
For example, the short domain URL of the social network Flickr
is \url{flic.kr}, where the long domain URL is \url{flicker.com}.
The short domain URL of Instagram is \url{instagr.am},
where the long domain URL is \url{instagram.com}, \emph{etc.}
We have created a list of all known short domain URLs for the 
considered media platforms so that the complete search query
for Twitter is the actual search term,
combined with this list of short domain URLs:

\emph{boston celtics AND (flic.kr OR instagr.am OR ...)}

\noindent The complete data flow is illustrated in the
architectural diagram in \autoref{fig:architecture}.
As a~side note, Twitter on its website now has its limited own
media extractor~\cite{wang2012twitter}
with support for some of of the media platforms,
however, our own media extractor goes beyond Twitter's offer.

\begin{figure}
  \centering
  \includegraphics[width=1.0\linewidth]{architecture.pdf}
  \caption{Overview of the media extractor:
    hybrid approach for the media item extraction process using
    a combination of API access and Web scraping}
  \label{fig:architecture}
\end{figure}

\section{Evaluation}
\label{sec:evaluation}

We have run experiments in the period of January 10--19, 2012
in which we have selected nine events.
For these events, we have collected media items and microposts
using our media extractor

\subsection{Events Considered}

We give a short overview of the nine selected events
in order to give the reader the necessary background knowledge.

\begin{description}
  \item[Assad Speech]
       On January 10, 2012, Syrian President Bashar al-Assad
       delivered a televised talk defending his
       government's actions and motivations, despite world
       pressure on his government for its 10-month
       crackdown on
       protesters\footnote{\url{http://www.cnn.com/2012/01/10/world/meast/syria-unrest/},
       accessed November 21, 2012}.
  \item[CES Las Vegas]
       The International Consumer Electronics Show (CES) is
       a major technology-related trade show held each January
       in the Las Vegas Convention Center. Not open to the public,
       the Consumer Electronics Association-sponsored show
       typically hosts previews of products and new product
       announcements\footnote{\url{http://www.cesweb.org/},
       accessed November 21, 2012}.
  \item[Costa Concordia Disaster]
       The Costa Concordia is an Italian cruise ship that hit
       a reef and partially sank on January 13, 2012 off the
       Italian coast. The vessel ran aground at Isola del Giglio,
       Tuscany, resulting in the evacuation of 4,211
       people\footnote{\url{http://en.wikipedia.org/wiki/Costa_Concordia_disaster},
       accessed November 21, 2012}.
  \item[Cut the Rope Launch]
       On January 10, 2012 during Microsoft's keynote at CES, the
       HTML5 version of the popular mobile game \textit{Cut the
       Rope} was announced. This is a sub-event of CES Las
       Vegas\footnote{\url{http://ces.cnet.com/8301-33377_1-57356403/},
       accessed November 21, 2012}.
  \item[Dixville Notch]
       Dixville Notch is an unincorporated village in Dixville
       township of Coos County, New Hampshire, USA, best known in
       connection with its longstanding middle-of-the-night vote in
       the U.S. presidential election. In a tradition that started
       in the 1960 election, all the eligible voters in Dixville
       Notch gather at midnight in the ballroom of The Balsams.
       This year, on January 10, 2012, the voters cast their
       ballots and the polls officially closed one minute
       later\footnote{\url{http://www.washingtonpost.com/2012/01/09/gIQANslKnP_story.html},
       accessed November 21, 2012}.
  \item[Free Mobile Launch]
       Free Mobile is a French mobile broadband company, part of
       the Iliad group. On January 10, 2012, a long-awaited mobile
       phone package for \EUR{19.99} with calls included to 40
       countries, texts, multimedia messages and Internet was
       announced by the Iliad group's Chief Strategy Officer,
       Xavier
       Niel\footnote{\url{http://www.nytimes.com/2012/01/11/technology/iliad-takes-aim-at-top-mobile-operators-in-france.html},
       accessed November 21, 2012}.
  \item[Blackout SOPA]
       The Stop Online Piracy Act (SOPA) is a bill of the United
       States proposed in 2011 to fight online trafficking in
       copyrighted intellectual property and counterfeit goods.
       On January 18, the English Wikipedia, Reddit, and several
       other Internet companies coordinated a service blackout
       to protest SOPA and its sister bill, the Protect IP Act.
       Other companies, including Google, posted links and
       images in an effort to raise
       awareness\footnote{\url{http://sopablackout.org/learnmore/},
       accessed November 21, 2012}.
  \item[Ubuntu TV Launch]
       Ubuntu TV by Canonical, based on the user interface Unity,
       is a variant of the Ubuntu operating system, designed to be
       a Linux distribution specially adapted for embedded systems
       in televisions. It was announced by Canonical on January
       10, 2012, at
       CES\footnote{\url{http://www.theverge.com/2012/1/9/2695387/ubuntu-tv-video-hands-on},
       accessed November 21, 2012}.
  \item[Christian Wulff Case]
       Since December 2011, former German President Christian
       Wulff faces controversy over discrepancies in statements
       about a loan while being governor of Lower Saxony.
       It was revealed that he had applied pressure
       on Springer Press to delay revelations on the issue until
       he was back from a visit abroad. When Wulff found out that
       a tabloid was going to break the story, he left a message
       on their voice mail in which he threatened to take legal
       action\footnote{\url{http://www.spiegel.de/international/germany/0,1518,804631,00.html},
       accessed November 21, 2012}.
\end{description}

%%%  4.2 Dataset  %%%
\subsection{Dataset}
Our data set contained 448 images with an average file size of $\sim$0.7MB and 143 videos (Table~2). Some videos are no longer available due to either an account termination or a video takedown by the user (Assad, Dixville). We observed that the process of image deduplication is by no means a solved issue. Content-based image retrieval (CBIR) uses features like color, texture, and shape to search images from large-scale databases. The same technique, however, can also be used for the deduplication of photographs~\cite{Pattabhi:RAICS11}. We used the PhotoSweeper CBIR-based image duplication detection software that allows for manual algorithm and threshold selection to detect duplicates in the dataset (Table~\ref{tab:duplicate-media}).

\begin{table*}[htbp]
  \centering{
  \small{
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
    \hline
    \multicolumn{1}{|c|}{\textbf{Social}} & \multicolumn{2}{c|}{\textbf{Assad}} & \multicolumn{2}{c|}{\textbf{CES}} &
    \multicolumn{2}{c|}{\textbf{Concordia}} & \multicolumn{2}{c|}{\textbf{Dixville}} & \multicolumn{2}{c|}{\textbf{Free}} &
    \multicolumn{2}{c|}{\textbf{Ropes}} & \multicolumn{2}{c|}{\textbf{SOPA}} & \multicolumn{2}{c|}{\textbf{Ubuntu}} &
    \multicolumn{2}{c|}{\textbf{Wulff}} \\
    \cline{2-19}
    \multicolumn{1}{|c|}{\textbf{Network}} & \textbf{I} & \textbf{V} & \textbf{I} & \textbf{V} & \textbf{I} & \textbf{V} &
    \textbf{I} & \textbf{V} & \textbf{I} & \textbf{V} & \textbf{I} & \textbf{V} & \textbf{I} & \textbf{V} & \textbf{I} &
    \textbf{V} & \textbf{I} & \textbf{V} \\
    \hline
    \textbf{Google+} & 3 & 2 & 5 & 3 & 15 & 1 & 4 & 1 & 6 & 0 & 5 & 1 & 5 & 0 & 6 & 1 & 7 & 0\\
    \textbf{MySpace} & 0 & 0 & 0 & 0 & 10+ & 0 & 9 & 0 & 1 & 0 & 6 & 0 & 0 & 0 & 0 & 0 & 8 & 0\\
    \textbf{Facebook} & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 2 & 0 & 0 & 0 & 0\\
    \textbf{Twitter} & 2 & 0 & 2 & 0 & 3 & 0 & 3 & 0 & 2 & 0 & 4 & 0 & 5 & 0 & 0 & 0 & 2 & 0\\
    \textbf{Instagram} & 0 & 0 & 20+ & 0 & 20+ & 0 & 0 & 0 & 20+ & 0 & 20+ & 0 & 20+ & 0 & 0 & 0 & 2 & 0\\
    \textbf{YouTube} & 0 & 10+ & 0 & 10+ & 0 & 10+ & 0 & 3 & 0 & 10+ & 0 & 10+ & 0 & 10+ & 0 & 10+ & 0 & 10+\\
    \textbf{Flickr} & 10+ & 0 & 10+ & 6 & 10+ & 10+ & 10+ & 10+ & 10+ & 0 & 10+ & 10+ & 10+ & 0 & 10+ & 9 & 10+ & 2\\
    \textbf{MobyPicture} & 0 & 0 & 1 & 0 & 4 & 0 & 0 & 0 & 2 & 0 & 20+ & 0 & 1 & 0 & 2 & 0 & 3 & 0\\
    \textbf{Twitpic} & 0 & 0 & 20+ & 0 & 18 & 0 & 1 & 0 & 20+ & 0 & 20+ & 0 & 19 & 0 & 2 & 0 & 20+ & 0\\
    \hline
    \textbf{Total} & 15 & 12 & 58 & 20 & 80 & 22 & 27 & 14 & 61 & 10 & 85 & 21 & 60 & 12 & 20 & 20 & 52 & 12\\
    \hline
  \end{tabular}
  }
  \label{tab:number-media}
  \caption{Number of images and videos collected for the 9 events (resp. \textbf{Assad Speech}, \textbf{CES Las Vegas}, \textbf{Costa Concordia Disaster}, \textbf{Dixville Notch}, \textbf{Free Mobile Launch}, \textbf{Cut the Rope Launch}, \textbf{Blackout SOPA}, \textbf{Ubuntu TV Launch} and \textbf{Christian Wulff Case}) grouped by social networks}
  }
\end{table*}

For each event, we have manually selected the best settings to limit the number of duplicate misses and false positives. The main problem with the dataset is its diversity. It ranges from entirely sharp screenshots in all sorts of formats (e.g. screenshots of the Google homepage for the Blackout SOPA event), to blurry cell phone images in standard photo formats (e.g. photos of the stage for the Free Mobile Launch event). A common performance tweak to speed up the duplication detection process is to shrink images to quadratic bitmaps. In the context of our dataset, however, this approach is counter productive, as a screenshot of a rectangular IAB $728 \times 90$ ``leaderboard'' banner is treated the same as a standard 3.1 megapixels ($2048 \times 1536$) cell phone photo. In practice, shrinking a wide rectangular banner to a square led to many incorrect results requiring manual deduplication with the Blackout SOPA event.

\begin{table*}[htbp]
  \begin{tabular}{|c|c|c||c|c|}
    \hline
    \textbf{Event} & \textbf{Exact Duplicate I} & \textbf{Loose Duplicate I} & \textbf{Exact Duplicate V} & \textbf{Loose Duplicate V}\\
    \hline
    Assad Speech & 0 image in 0 seq & 2 images in 1 seq & 0 video in 0 seq & 2 videos in 1 seq\\
    CES Las Vegas & 0 image in 0 seq & 9 images in 3 seq & 0 video in 0 seq & 2 videos in 1 seq\\
    Costa Concordia & 0 image in 0 seq & 6 images in 3 seq & 0 video in 0 seq & 0 video in 0 seq\\
    Cut the Rope Launch & 2 images in 1 seq & 15 images in 5 seq & 0 video in 0 seq & 14 videos in 3 seq\\
    Dixville Notch & 2 images in 1 seq & 2 images in 1 seq & 2 videos in 1 seq & 0 video in 0 seq\\
    Free Mobile Launch & 2 images in 1 seq & 16 images in 7 seq & 0 video in 0 seq & 0 video in 0 seq\\
    Blackout SOPA & 0 image in 0 seq & 14 images in 4 seq & 2 videos in 1 seq & 0 video in 0 seq\\
    Ubuntu TV Launch & 0 image in 0 seq & 5 images in 1 seq & 4 videos in 1 seq & 9 videos in 4 seq\\
    Christian Wulff Case & 4 images in 2 seq & 0 image in 0 seq & 0 video in 0 seq & 0 video in 0 seq\\
    \hline
  \end{tabular}
  \label{tab:duplicate-media}
  \caption{Exact and loose duplicate images (I) and videos (V) per event}
\end{table*}

%Some videos are false positives (Cut the rope launch, Dixville, Free mobile, Ubuntu).


\begin{figure*}
\begin{tabular}{p{\textwidth}}
\eventtitle{Blackout SOPA}
\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{sopa/looseduplicate1.jpg}
		\includegraphics[height=\thumbheight]{sopa/looseduplicate2.jpg}
		\includegraphics[height=\thumbheight]{sopa/looseduplicate3.jpg}
		\includegraphics[height=\thumbheight]{sopa/looseduplicate4.jpg}
		\includegraphics[height=\thumbheight]{sopa/looseduplicate5.jpg}
		\includegraphics[height=\thumbheight]{sopa/looseduplicate6.jpg}
	\end{thumbsequence}
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{sopa/looseduplicate7.png}
		\includegraphics[height=\thumbheight]{sopa/looseduplicate8.jpg}
	\end{thumbsequence}
	\newstrip
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{sopa/looseduplicate9.png}
		\includegraphics[height=\thumbheight]{sopa/looseduplicate10.png}
		\includegraphics[height=\thumbheight]{sopa/looseduplicate11.jpg}
		\includegraphics[height=\thumbheight]{sopa/looseduplicate12.jpg}
	\end{thumbsequence}
	\begin{thumbsequence}
		\setlength\fboxsep{0pt}
		\setlength\fboxrule{0.1mm}
		\fbox{\includegraphics[height=\thumbheight]{sopa/looseduplicate13.png}}
		\fbox{\includegraphics[height=\thumbheight]{sopa/looseduplicate14.jpg}}
\end{thumbsequence}
\end{tabular}

\vspace{.5em}
	
\begin{tabular}{p{\textwidth}}
\eventtitle{Christian Wulff Case}
	\begin{thumbsequence}
		\doublebox{\includegraphics[height=\thumbheight]{wulff/exactduplicate1.jpg}}
		\doublebox{\includegraphics[height=\thumbheight]{wulff/exactduplicate2.jpg}}
	\end{thumbsequence}
	\begin{thumbsequence}
		\doublebox{\includegraphics[height=\thumbheight]{wulff/exactduplicate3.jpg}}
		\doublebox{\includegraphics[height=\thumbheight]{wulff/exactduplicate4.jpg}}
	\end{thumbsequence}
\end{tabular}

\vspace{.5em}

\begin{tabular}{p{.5\textwidth}p{.5\textwidth}}
\eventtitle{Dixville Notch}
	\begin{thumbsequence}
		\doublebox{\includegraphics[height=\thumbheight]{dixville/exactduplicate1.jpg}}
		\doublebox{\includegraphics[height=\thumbheight]{dixville/exactduplicate2.jpg}}
	\end{thumbsequence}
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{dixville/looseduplicate1.jpg}
		\includegraphics[height=\thumbheight]{dixville/looseduplicate2.jpg}
	\end{thumbsequence}
	&
\vspace{-3pt}
\eventtitle{Assad Speech}
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{assad/looseduplicate1.jpg}
		\includegraphics[height=\thumbheight]{assad/looseduplicate2.jpg}
	\end{thumbsequence}
\end{tabular}

\vspace{.5em}

\begin{tabular}{p{\textwidth}}
\eventtitle{Free Mobile Launch}
	\begin{thumbsequence}
		\doublebox{\includegraphics[height=\thumbheight]{free/exactduplicate1.jpg}}
		\doublebox{\includegraphics[height=\thumbheight]{free/exactduplicate2.jpg}}
	\end{thumbsequence}
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{free/looseduplicate1.png}
		\includegraphics[height=\thumbheight]{free/looseduplicate2.png}
	\end{thumbsequence}
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{free/looseduplicate7.jpg}
		\includegraphics[height=\thumbheight]{free/looseduplicate8.jpg}
	\end{thumbsequence}
	\\[4pt]
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{free/looseduplicate15.jpg}
		\includegraphics[height=\thumbheight]{free/looseduplicate16.png}
	\end{thumbsequence}
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{free/looseduplicate9.jpg}
		\includegraphics[height=\thumbheight]{free/looseduplicate10.jpg}
		\includegraphics[height=\thumbheight]{free/looseduplicate11.jpg}
	\end{thumbsequence}
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{free/looseduplicate3.jpg}
		\includegraphics[height=\thumbheight]{free/looseduplicate4.jpg}
	\end{thumbsequence}
	\newstrip
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{free/looseduplicate12.jpg}
		\includegraphics[height=\thumbheight]{free/looseduplicate13.jpg}
		\includegraphics[height=\thumbheight]{free/looseduplicate14.jpg}
	\end{thumbsequence}
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{free/looseduplicate5.jpg}
		\includegraphics[height=\thumbheight]{free/looseduplicate6.jpg}
	\end{thumbsequence}
\end{tabular}

\vspace{.5em}

\begin{tabular}{p{\textwidth}}
\eventtitle{Costa Concordia Disaster}
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{concordia/looseduplicate1.jpg}
		\includegraphics[height=\thumbheight]{concordia/looseduplicate2.jpg}
	\end{thumbsequence}
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{concordia/looseduplicate3.jpg}
		\includegraphics[height=\thumbheight]{concordia/looseduplicate4.jpg}
	\end{thumbsequence}
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{concordia/looseduplicate5.jpg}
		\includegraphics[height=\thumbheight]{concordia/looseduplicate6.jpg}
	\end{thumbsequence}
\end{tabular}

\vspace{.5em}

\begin{tabular}{p{\textwidth}}
\eventtitle{CES Las Vegas}
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{ces/looseduplicate1.jpg}
		\includegraphics[height=\thumbheight]{ces/looseduplicate2.jpg}
		\includegraphics[height=\thumbheight]{ces/looseduplicate3.jpg}
		\includegraphics[height=\thumbheight]{ces/looseduplicate4.jpg}
		\includegraphics[height=\thumbheight]{ces/looseduplicate5.jpg}
	\end{thumbsequence}
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{ces/looseduplicate6.jpg}
		\includegraphics[height=\thumbheight]{ces/looseduplicate7.jpg}
	\end{thumbsequence}
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{ces/looseduplicate8.jpg}
		\includegraphics[height=\thumbheight]{ces/looseduplicate9.jpg}
	\end{thumbsequence}
\end{tabular}

\vspace{.5em}

\begin{tabular}{p{.5\textwidth}p{.5\textwidth}}
	\eventtitle{Cut the Rope Launch}
	\begin{thumbsequence}
		\doublebox{\includegraphics[height=\thumbheight]{ropes/exactduplicate1.jpg}}
		\doublebox{\includegraphics[height=\thumbheight]{ropes/exactduplicate2.jpg}}
	\end{thumbsequence}
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{ropes/looseduplicate5.jpg}
		\includegraphics[height=\thumbheight]{ropes/looseduplicate6.jpg}
		\includegraphics[height=\thumbheight]{ropes/looseduplicate7.jpg}
		\includegraphics[height=\thumbheight]{ropes/looseduplicate8.jpg}
		\includegraphics[height=\thumbheight]{ropes/looseduplicate9.jpg}
	\end{thumbsequence}
	\newline\vspace{-.5em}\newline
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{ropes/looseduplicate12.jpg}
		\includegraphics[height=\thumbheight]{ropes/looseduplicate13.jpg}
	\end{thumbsequence}
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{ropes/looseduplicate14.jpg}
		\includegraphics[height=\thumbheight]{ropes/looseduplicate15.jpg}
	\end{thumbsequence}
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{ropes/looseduplicate10.jpg}
		\includegraphics[height=\thumbheight]{ropes/looseduplicate11.jpg}
	\end{thumbsequence}
	\newstrip
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{ropes/looseduplicate1.jpg}
		\includegraphics[height=\thumbheight]{ropes/looseduplicate2.jpg}
		\includegraphics[height=\thumbheight]{ropes/looseduplicate3.png}
		\includegraphics[height=\thumbheight]{ropes/looseduplicate4.png}
	\end{thumbsequence}
	&
\eventtitle{Ubuntu TV launch}
	\begin{thumbsequence}
		\includegraphics[height=\thumbheight]{ubuntu/looseduplicate1.jpg}
		\includegraphics[height=\thumbheight]{ubuntu/looseduplicate2.jpg}
		\newstrip
		\includegraphics[height=\thumbheight]{ubuntu/looseduplicate3.jpg}
		\includegraphics[height=\thumbheight]{ubuntu/looseduplicate4.jpg}
		\newstrip
		\includegraphics[height=\thumbheight]{ubuntu/looseduplicate5.png}
	\end{thumbsequence}
\end{tabular}
\caption{Results of the image deduplication (exact and loose duplicate) for the 9 selected events}
\label{fig:sequences}
\end{figure*}

%%%  4.4 Generating Media Galleries  %%%
\subsection{Generating Media Galleries}
Once the media items are ranked, it is possible to generate media galleries and build visual summaries. Popular media items can be displayed bigger, longer, or with a special decoration like a thicker border in comparison to less popular media items. For videos, the audio part poses a challenge. In our experiments, we observe that intermixing the audio of all videos of an event often generates a very characteristic ``noise cloud''. A good example is the Assad Speech event, where a mix of Arabic voices blends nicely with the speech of a US politician. A different example is the CES Las Vegas event, where the atmosphere of a big exposition with music, announcements, and technical analysis becomes alive.

%%%%%%%%%%%%%%%%%%%%%%%%%
%%%  5. Related Work  %%%
%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Related Work}                                                      \label{sec:related-work}
% Separate related work in fields:
% - media item collection from social networks
% - event summarization
% Highlight what Twitter is doing (most popular image/video)
% Google news top stories
% Automatic gallery creation

A~first category of related work includes research that aims to collect, align, and organize media for trends or events.
Liu \emph{et al.} combine semantic inferencing and visual analysis to automatically find media to illustrate events~\cite{Liu:ICMR11}.
They interlink large datasets of event metadata and media with the Linking Open Data Cloud~\cite{LODcloud}.
Approaches for alignment use visual, temporal, and spacial similarity measures to map multiple photo streams of the same events~\cite{Yang2011}.
Other ways to collect and order media from social networks use user-driven metadata such as geospatial information~\cite{Crandall}.

Another relevant work area is duplicate and near-duplicate media detection. Work on ordinal measures for image correspondence started in the last decade of the 20\superscript{th}~century~\cite{Bhat}. Recently, Chum \emph{et al.} have proposed a near-duplicate image detection method using MinHash and tf--idf weighting~\cite{Chum}. A~method for both images and video has been proposed by Yang \emph{et al.}~\cite{Yang}. Specialized methods for video exist as well~\cite{Min, Wu}, an excellent survey of which has been conducted by Lian \emph{et al.}~\cite{Lian}.

When unique media items have been collected, the remaining task is to summarize events by selecting the most relevant media fragments. Fabro and B\"osz\"orm\'enyi~\cite{Fabro:MMM12} detail the summarization and presentation of events from content retrieved from social media. Nowadays, many domain-specific methods already exhibit good accuracy, for example in the sports domain~\cite{Li1,Li2}. However, the challenge in this field is to find methods that are content-agnostic. Methods that exploit semantic information~(\emph{e.g.} \cite{Chen}) will likely provide high-quality results in the future, but today's most relevant summaries are produced by user interaction~\cite{Olsen}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%  6. Conclusion and Future Work  %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion and Future Work}                                        \label{sec:conclusion}
In this section, we presented a generic media extractor for gathering media items shared on social networks and illustrating known events. We proposed a common schema for aligning the search results of these platforms. We further described a full processing chain of the media items that includes machine translation, POS tagging, named entity disambiguation and media item deduplication. We show how media items can be ranked in order to generate visual summaries that convey the feeling of the wisdom of the crowd for a known event.

Our implementation for extracting visual media and associated textual messages covers already most of the Western social networks. We plan to support more social networks used in other parts of the world while improving the Web scrapers in order to significantly improve the quantity and diversity of media and messages shared for an event. Multimedia analysis techniques should be better integrated in the processing chain as this will create a multi-modal environment where different factors are used to organize social content. Hence, content deduplication and visual quality metrics (sharpness, contrast\ldots) can be used to rank the media items. Furthermore, the identification of the original content can allow users to choose a balance between popularity (favor omnipresent content) and originality (promote rare content).

Context-aware multimedia analysis will likely bring a new range of parameters into play since many media items contain a message that is complementary to the text. For example, facial detection~\cite{ViolaJones} and eventually recognition~\cite{Wright} can signify the presence of specific people in a media fragment.
As visual recognition systems grow more powerful, more objects will eventually be recognizable by machines~\cite{Serre}, which would allow generating \emph{visual hashtags} that describe the content \emph{inside} of the media item. Extracted features in all three categories~(\emph{textual} -- from the micropost, \emph{visual} -- from the media item, and \emph{social} -- from the social network in the form of ReTweets, Likes, +1s\ldots) can also serve as ranking criteria, be it in isolation, or in combination by introducing a ranking formula. As a result, this would also positively influence the diversity of automated summarizations.

Nonetheless, it remains important to view the media and the associated text as a whole, since the text could convey a sentiment about or an explanation of the visual data. Using named entity recognition~\cite{NERD,AddingMeaningToMicroposts}, the important semantic elements in the message text can be identified. The content of the message could subsequently be used to narrow down the search space for visual factors enabling cross-fertilization between the textual and visual analysis, which results in effective context-aware analysis possibilities~\cite{verborgh_mtap_2011}.

\section*{Chapter Notes}
This chapter is partly based on the following publications:
\todo{Add publications}