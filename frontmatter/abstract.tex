\begin{abstracts}

\textbf{(i) Mobile devices and social networks are omnipresent}

Mobile devices such as smartphones, tablets, or digital cameras
together with social networks enable people to create,
share, and consume enormous amounts of media items
like videos or photos, both on the road, or at home.
Such mobile devices---by pure definition---accompany
their owners almost wherever they may go.
In consequence, mobile devices are omnipresent
at all sorts of events.
Exemplary events can be keynote speeches at conferences,
music concerts in stadiums,
or even natural catastrophes like earthquakes
that affect whole areas or countries.
At such events---given a~stable network connection---part of
the event-related media items are published on social networks,
both as the event happens, or afterwards,
once a~stable network connection has been established again.

\textbf{(ii) Finding representative media items
for an event is hard}

Common media item search operations,
for example, searching for \emph{the} official video clip
for a~certain hit record on an online video platform,
can in the simplest case be achieved based on potentially
shallow human-generated metadata,
or based on more profound content analysis techniques
like Optical Character Recognition,
Automatic Speech Recognition,
or Acoustic Fingerprinting.
More advanced scenarios, however, like retrieving all
(or just the most representative) media items
that were created at a~given event
with the objective of creating \emph{event summaries} or
\emph{media item compilations} covering the event in question,
are hard, if not impossible, to fulfill at large scale.
The main research question of this thesis
can be formulated as follows.

\textbf{(iii) Research question}

\textit{``Can user-customizable media galleries
that summarize given events be\linebreak
created solely based on textual and multimedia data
from social networks?''}

\textbf{(iv) Contributions}

In this thesis, we develop and evaluate
a~novel interactive application and related methods
for media item enrichment,
leveraging social networks, utilizing the Web of Data,
techniques known from Content-based Image Retrieval~(CBIR)
and Content-based Video Retrieval~(CBVR),
and fine-grained media item addressing schemes
like Media Fragments URIs,
to provide a~scalable and near realtime solution
to realize the abovementioned scenario
of event summarization and media item compilation.

\textbf{(v) Methodology}

For any event with given event title(s),
(potentially vague) event location(s), and
(arbitrarily fine-grained) event date(s), 
our approach can be divided in the following six steps.

\begin{enumerate}
  \item Via the textual search functionality of
        different social networks,
        we retrieve a~list of potentially event-relevant
        microposts that either contain media items directly,
        or that provide links to media items
        on external media item hosting platforms.
  \item Using third party
        Natural Language Processing (NLP) tools,
        we recognize and disambiguate named entities
        in the microposts to predetermine their relevancy.
  \item We extract the binary media item data
        from social networks or media item hosting platforms
        and relate it to the originating microposts.
  \item Using CBIR and CBVR techniques, we first deduplicate
        exact and near-duplicate media items,
        and then cluster similar media items.
  \item We rank the deduplicated and clustered list
        of media items and their related microposts
        according to well-defined ranking criteria.
  \item In order to to generate interactively user-customizable
        media galleries that visually and audibly summarize the
        event in question, we compile the top-$n$ ranked
        media items and microposts in an aesthetic way.
\end{enumerate}
\end{abstracts}
